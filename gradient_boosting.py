import re

import pandas as pd
from lime.lime_tabular import LimeTabularExplainer
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from joblib import Parallel, delayed


def create_model(features, labels, all_permissions, all_api_calls):
    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)
    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)
    clf.fit(X_train, y_train)

    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print("Accuracy:", accuracy)

    gb_model = GradientBoostingClassifier()
    gb_model.fit(X_train, y_train)
    y_prediction = gb_model.predict(X_test)

    print("Training the gradient boosting model")

    X_train = pd.DataFrame(X_train)
    explainer = LimeTabularExplainer(X_train.values, feature_names=X_train.columns.values,
                                     class_names=['benign', 'malware'])
    X_test = pd.DataFrame(X_test)
    feature_weights = {}
    print("Explaining every feature")

    explanations = Parallel(n_jobs=-1)(
        delayed(generate_explanation)(explainer, gb_model, X_test.iloc[i]) for i in range(len(X_test))
    )

    # Collect the feature weights from the explanations
    for exp in explanations:
        for feature, weight in exp.as_list():
            if feature in feature_weights:
                feature_weights[feature].append(weight)
            else:
                feature_weights[feature] = [weight]

    # Analyze the feature weights
    salient_features = []

    for feature, weights in feature_weights.items():
        avg_weight = sum(weights) / len(weights)
        salient_features.append((feature, avg_weight))

    # Sort the features based on average weight in descending order
    salient_features.sort(key=lambda x: x[1], reverse=True)

    print("Finding the top 5 salient features")

    # Print the top-k salient features
    k = 5
    for feature, weight in salient_features[:k]:
        feature_name = get_feature_name(feature, all_permissions, all_api_calls)
        print(f"Feature: {feature_name}")
        print(f"Average Weight: {weight}")
        print("------------------------------")

    return clf


def generate_explanation(explainer, model, instance):
    return explainer.explain_instance(instance.values, model.predict_proba, num_features=10)


def get_feature_name(feature_idx, all_permissions, all_api_calls):
    if isinstance(feature_idx, str):
        match = re.search(r'\d+', feature_idx)
        if match:
            feature_idx = int(match.group())

    if isinstance(feature_idx, int):
        all_permissions = list(all_permissions)
        all_api_calls = list(all_api_calls)
        if 0 <= feature_idx < len(all_permissions):
            return f"Permission: {all_permissions[feature_idx]}"
        elif len(all_permissions) <= feature_idx < len(all_permissions) + len(all_api_calls):
            api_idx = feature_idx - len(all_permissions)
            return f"API Call: {all_api_calls[api_idx]}"

    return "Unknown Feature"
